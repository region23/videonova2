Отлично, раз Фаза 2 завершена и интерфейс готов к сбору необходимой информации (URL, язык оригинала, язык перевода, папка для сохранения), переходим к **Фазе 3: Реализация Основного Конвейера Обработки (Core Processing Pipeline)**.

**Цель:** Связать воедино бэкенд-сервисы, созданные в Фазе 1, в последовательный конвейер обработки в главном процессе (main process) Electron. Этот конвейер будет запускаться через IPC-вызов (`startProcessing`), инициированный пользователем в Фазе 2. Он должен оркестрировать выполнение шагов: скачивание видео -> извлечение аудио -> распознавание речи (STT) -> перевод -> синтез речи (TTS) -> слияние аудио с видео -> сохранение результата.

**Фокус на Best Practices (Январь 2025):**
*   **Оркестрация:** Создание центрального модуля-оркестратора для управления потоком задач.
*   **Асинхронность:** Интенсивное использование `async/await` для управления асинхронными операциями (I/O, API-вызовы, дочерние процессы).
*   **Обработка ошибок:** Реализация надежной обработки ошибок на каждом шаге конвейера с возможностью прервать выполнение.
*   **Управление данными:** Передача промежуточных результатов (пути к файлам, текст) между шагами.
*   **Модульность:** Использование интерфейсов сервисов (`ISttService`, `ITranslationService` и т.д.), определенных в Фазе 1, для слабой связности.
*   **Управление временными файлами:** Создание и очистка временных файлов, необходимых для промежуточных шагов.

---

**Шаг 3.1: Проектирование Модуля Оркестратора Конвейера**

*   **Задача:** Создать класс или модуль в main процессе, который будет управлять всем процессом обработки для одного видео.
*   **Действия:**
    1.  Создать файл `src/main/processing/pipelineOrchestrator.ts`.
    2.  Определить класс `PipelineOrchestrator`.
    3.  Конструктор класса должен принимать все необходимые параметры:
        *   `videoUrl: string`
        *   `sourceLanguage: string` (для STT)
        *   `targetLanguage: string` (для перевода и TTS)
        *   `outputFolderPath: string`
        *   `apiKey: string` (или способ его получения из `settingsManager`)
        *   Ссылки на экземпляры сервисов (ytDlpService, ffmpegService, sttService, translationService, ttsService). *Идеально:* передавать сервисы, реализующие интерфейсы (`ISttService` и т.д.).
    4.  Определить внутреннее состояние оркестратора: `status` (`idle`, `downloading`, `extracting`, `transcribing`, ..., `merging`, `completed`, `failed`), `currentStep`, `errorMessage`, `resultPath`.
    5.  Определить основной публичный метод, например, `async run(): Promise<string>` (возвращает путь к итоговому файлу) или `async run(): Promise<void>` (результат сохраняется в `resultPath`).
*   **Инструменты:** TypeScript.
*   **Результат:** Структура класса-оркестратора, готовая к наполнению логикой выполнения шагов.

---

**Шаг 3.2: Реализация Управления Временными Файлами**

*   **Задача:** Обеспечить создание уникальной временной директории для каждого задания обработки и её последующую очистку.
*   **Действия:**
    1.  В конструкторе `PipelineOrchestrator` или в начале метода `run()`:
        *   Использовать `os.tmpdir()` и `fs.promises.mkdtemp()` для создания уникальной временной папки (например, `videonova-job-<random>`). Сохранить путь к ней в состоянии оркестратора (`this.tempDir`).
    2.  Все промежуточные файлы (скачанное видео, аудио, VTT, синтезированная речь) должны сохраняться внутри этой `this.tempDir`.
    3.  Реализовать приватный метод `async cleanup()` в `PipelineOrchestrator`, который будет использовать `fs.promises.rm(this.tempDir, { recursive: true, force: true })` для удаления временной папки со всем содержимым.
    4.  Обеспечить вызов `cleanup()` в конце метода `run()` как при успешном завершении, так и при ошибке (например, с использованием блока `finally`).
*   **Инструменты:** Node.js `os`, `fs.promises`.
*   **Результат:** Надежный механизм создания и удаления временных файлов для каждого задания.

---

**Шаг 3.3: Интеграция Шага Скачивания Видео (yt-dlp)**

*   **Задача:** Добавить в метод `run()` оркестратора вызов `ytDlpService` для скачивания видео.
*   **Действия:**
    1.  В методе `run()`, внутри блока `try...catch`:
        *   Установить статус `this.status = 'downloading'`.
        *   Вызвать `this.ytDlpService.getVideoInfo(this.videoUrl)` для получения метаданных (например, названия видео для формирования имени выходного файла, файла субтиров, кода языка оригинальной аудиодорожки).
        *   Выбрать подходящий формат для скачивания (например, лучшее видео + лучший звук).
        *   Вызвать `await this.ytDlpService.downloadMedia(this.videoUrl, formatCode, downloadPath)` где `downloadPath` - это путь к файлу внутри `this.tempDir`.
        *   Сохранить путь к скачанному видеофайлу в состоянии оркестратора (`this.originalVideoPath`).
*   **Инструменты:** `PipelineOrchestrator`, `ytDlpService`.
*   **Результат:** Первый шаг конвейера - скачивание видео - реализован и интегрирован в оркестратор.

---

**Шаг 3.4: Интеграция Шага Извлечения Аудио (ffmpeg)**

*   **Задача:** Добавить в `run()` вызов `ffmpegService` для извлечения аудиодорожки из скачанного видео.
*   **Действия:**
    1.  В методе `run()`, после шага скачивания:
        *   Установить статус `this.status = 'extracting'`.
        *   Определить путь для выходного аудиофайла (`extractedAudioPath` внутри `this.tempDir`).
        *   Вызвать `await this.ffmpegService.extractAudio(this.originalVideoPath, extractedAudioPath)`.
        *   Сохранить путь к извлеченному аудиофайлу в состоянии (`this.extractedAudioPath`).
*   **Инструменты:** `PipelineOrchestrator`, `ffmpegService`.
*   **Результат:** Шаг извлечения аудио добавлен в конвейер.

---

**Шаг 3.5: Интеграция Шага Распознавания Речи (STT - Online)**

*   **Задача:** Добавить вызов сервиса STT (используя интерфейс `ISttService`, реализованный `openAiClient`) для получения текста из аудио. Шаг выполняется только в том случае, если на предыдущем шаге не удалось скачать оригинальные субтитры.
*   **Действия:**
    1.  В методе `run()`, после извлечения аудио:
        *   Установить статус `this.status = 'transcribing'`.
        *   Получить API ключ (из конструктора или настроек).
        *   Вызвать `await this.sttService.transcribe(this.extractedAudioPath, this.sourceLanguage)` (передавая также API ключ, если сервис его требует напрямую).
        *   Сохранить результат транскрипции (текст или структуру VTT/SRT) в состоянии (`this.transcriptionResult`).
*   **Инструменты:** `PipelineOrchestrator`, `ISttService` (реализация `openAiClient`).
*   **Результат:** Шаг распознавания речи (пока только онлайн-версия) интегрирован.

---

**Шаг 3.6: Интеграция Шага Перевода (Online)**

*   **Задача:** Добавить вызов сервиса перевода (используя `ITranslationService`, реализованный `openAiClient`).
*   **Действия:**
    1.  В методе `run()`, после транскрипции:
        *   Установить статус `this.status = 'translating'`.
        *   Получить API ключ.
        *   Извлечь текст из `this.transcriptionResult`.
        *   Вызвать `await this.translationService.translate(originalText, this.targetLanguage, this.sourceLanguage)`.
        *   Сохранить переведенный текст в состоянии (`this.translatedText`).
*   **Инструменты:** `PipelineOrchestrator`, `ITranslationService` (реализация `openAiClient`).
*   **Результат:** Шаг перевода текста (пока онлайн) добавлен в конвейер.

---

**Шаг 3.7: Интеграция Шага Синтеза Речи (TTS - Online)**

*   **Задача:** Добавить вызов сервиса TTS (используя `ITtsService`, реализованный `openAiClient`) для генерации аудио из переведенного текста.
*   **Действия:**
    1.  В методе `run()`, после перевода:
        *   Установить статус `this.status = 'synthesizing'`.
        *   Получить API ключ.
        *   Определить путь для выходного синтезированного аудиофайла (`synthesizedAudioPath` внутри `this.tempDir`).
        *   Выбрать голос TTS (можно пока захардкодить или добавить простой выбор в UI позже).
        *   Вызвать `await this.ttsService.synthesize(this.translatedText, voice, synthesizedAudioPath)`.
        *   Сохранить путь к синтезированному аудио в состоянии (`this.synthesizedAudioPath`).
*   **Инструменты:** `PipelineOrchestrator`, `ITtsService` (реализация `openAiClient`).
*   **Результат:** Шаг синтеза речи (пока онлайн) интегрирован.

---

**Шаг 3.8: Интеграция Шага Слияния Аудио и Видео (ffmpeg)**

*   **Задача:** Добавить вызов `ffmpegService` для создания финального видеофайла путем объединения оригинального видео, новой синтезированной аудиодорожки и оригинальной аудиодорожки (если она еще не вшита в видео), оригинальных субтитров, переведенных субтитров.
*   **Действия:**
    1.  В методе `run()`, после синтеза речи:
        *   Установить статус `this.status = 'merging'`.
        *   Сформировать имя для финального файла (например, на основе оригинального имени + язык) и полный путь в *целевой папке*, указанной пользователем (`finalOutputPath`).
        *   Вызвать `await this.ffmpegService.mergeAudioVideo(this.originalVideoPath, this.synthesizedAudioPath, finalOutputPath)`. Возможно, потребуется передать дополнительные опции в `mergeAudioVideo` для копирования видеодорожки (`-c:v copy`) и кодирования аудио (`-c:a aac` или другое).
        *   Сохранить путь к финальному файлу в состоянии (`this.resultPath`).
*   **Инструменты:** `PipelineOrchestrator`, `ffmpegService`.
*   **Результат:** Шаг создания финального видеофайла интегрирован.

---

**Шаг 3.9: Обновление Обработчика IPC (`startProcessing`)**

*   **Задача:** Модифицировать обработчик IPC, созданный в Фазе 2, чтобы он создавал и запускал экземпляр `PipelineOrchestrator`.
*   **Действия:**
    1.  В `src/main/index.ts`, в обработчике `ipcMain.handle(Channels.START_PROCESSING, async (event, args) => { ... })`:
        *   Извлечь параметры из `args` (`url`, `sourceLanguage`, `targetLanguage`, `outputFolderPath`).
        *   Получить необходимые сервисы (можно создать их один раз при старте приложения и передавать).
        *   Получить API ключ из `settingsManager`. Проверить, что он есть, иначе вернуть ошибку.
        *   Создать новый экземпляр: `const orchestrator = new PipelineOrchestrator(args.url, ..., apiKey, services);`
        *   Запустить конвейер: `await orchestrator.run();` внутри `try...catch`.
        *   Вернуть результат в рендерер:
            *   При успехе: `{ success: true, resultPath: orchestrator.resultPath }`.
            *   При ошибке: `{ success: false, error: orchestrator.errorMessage || 'Unknown error occurred' }`.
*   **Инструменты:** Electron `ipcMain`, `PipelineOrchestrator`.
*   **Результат:** IPC-вызов из UI теперь запускает полный (пока только онлайн) конвейер обработки видео на бэкенде.

---

**Шаг 3.10: Базовая Обработка Ошибок в Оркестраторе**

*   **Задача:** Обеспечить, чтобы ошибки, возникающие на любом шаге конвейера, корректно перехватывались, прерывали выполнение и записывали информацию об ошибке.
*   **Действия:**
    1.  Обернуть всю последовательность вызовов `await this.service.method(...)` в методе `run()` оркестратора в один большой блок `try...catch (error)`.
    2.  В блоке `catch`:
        *   Установить статус `this.status = 'failed'`.
        *   Записать сообщение об ошибке `this.errorMessage = error instanceof Error ? error.message : String(error)`.
        *   Залогировать полную ошибку в консоль main процесса (`console.error(...)`).
        *   *Не пробрасывать* ошибку дальше, так как `run()` должен завершиться, и состояние ошибки будет возвращено через IPC в Шаге 3.9.
    3.  Убедиться, что блок `finally` (для вызова `cleanup()`) выполняется независимо от того, произошла ошибка или нет.
*   **Инструменты:** TypeScript (`try...catch`, `finally`).
*   **Результат:** Оркестратор теперь может перехватывать ошибки на любом шаге, останавливать процесс и сохранять сообщение об ошибке для последующей передачи в UI (хотя детальное отображение будет в след. фазах).

---

**Итог Фазы 3:**
К концу этой фазы основной конвейер обработки видео полностью реализован в main процессе. Он способен:
1.  Принять запрос от UI через IPC.
2.  Последовательно выполнить все шаги: скачивание, извлечение аудио, онлайн STT, онлайн перевод, онлайн TTS, слияние видео.
3.  Управлять временными файлами.
4.  Сохранить итоговый файл в указанную пользователем папку.
5.  Обработать ошибки на любом этапе и вернуть базовый статус успеха/неудачи в UI.

**Ограничения на данном этапе:**
*   Используются **только онлайн-сервисы** (OpenAI). Оффлайн-модели не интегрированы.
*   Не реализованы опциональные шаги (Demucs для разделения вокала, Soundtouch для подгонки таймингов).
*   Нет **детальной обратной связи о прогрессе** для пользователя во время выполнения (UI все еще показывает только "Обработка начата...").
*   Обработка ошибок в UI все еще базовая (только сообщение об успехе/неудаче по завершении).

Следующая фаза (Фаза 4) будет сфокусирована на улучшении пользовательского опыта путем добавления детального отслеживания прогресса и его отображения в UI.