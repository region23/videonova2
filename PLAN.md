**Цель:** Создать кроссплатформенное десктопное приложение VideoNova согласно ТЗ.
**Исполнитель:** ИИ-агент (с возможностью запроса помощи/валидации у человека).
**Основные Технологии:** Electron, Node.js, React, TypeScript, Vite, Ant Design, yt-dlp, ffmpeg, Demucs, Soundtouch, OpenAI API, Whisper/Vosk, Fish Speech, Ollama.
## Всегда обращайся к этому плану, если есть сомнения. Либо уточняй у пользователя.

---

**План Реализации VideoNova**

**Фаза 0: Инициализация проекта и настройка окружения**

*   **Шаг 0.1: Создание структуры проекта**
    *   **Действие:** Инициализировать новый проект с использованием Vite и шаблона React + TypeScript.
    *   **Инструменты:** `npm create vite@latest videonova-app -- --template react-ts`
    *   **Результат:** Базовая структура React/TS/Vite проекта.
*   **Шаг 0.2: Интеграция Electron**
    *   **Действие:** Добавить Electron в проект. Настроить `package.json` для запуска и сборки Electron-приложения (`main` script, build команды). Создать основной файл Electron (`main.ts` или аналогичный) и файл preload (`preload.ts`). Настроить Vite для работы с Electron (например, используя `vite-plugin-electron`).
    *   **Инструменты:** `npm install --save-dev electron`, `vite-plugin-electron` (или аналогичный).
    *   **Конфигурация:** Настроить `vite.config.ts`, `electron/main.ts`, `electron/preload.ts`.
    *   **Результат:** Базовое Electron-приложение, способное отображать React-фронтенд.
*   **Шаг 0.3: Установка основных зависимостей**
    *   **Действие:** Установить NodeJS (v22.x), React (v19), TypeScript, Ant Design (v5.0).
    *   **Инструменты:** `npm install react@19 react-dom@19 antd@5`
    *   **Конфигурация:** Настроить `tsconfig.json` для соответствия требованиям проекта. Интегрировать стили Ant Design.
    *   **Результат:** Проект с установленными основными библиотеками фронтенда и настроенным TypeScript.
*   **Шаг 0.4: Настройка IPC**
    *   **Действие:** Настроить базовую межпроцессную коммуникацию (IPC) между основным процессом Electron (бэкенд) и процессом рендерера (фронтенд) через preload скрипт. Определить базовый API для взаимодействия.
    *   **Инструменты:** `ipcMain`, `ipcRenderer`, `contextBridge` (в `preload.ts`).
    *   **Результат:** Возможность вызывать функции бэкенда из фронтенда и получать ответы/события.

**Фаза 1: Бэкенд - Интеграция внешних утилит и API (Базовые обертки)**

*   **Шаг 1.1: Обертка для `yt-dlp`**
    *   **Действие:** Создать модуль (класс или набор функций) в бэкенде Node.js для взаимодействия с утилитой `yt-dlp` через `child_process`. Реализовать функции для:
        *   Получения информации о видео (`--dump-json`).
        *   Скачивания видео/аудио (`-f`, `-o`).
        *   Скачивания субтитров (`--write-subs`, `--sub-lang`).
    *   **Обработка:** Парсинг вывода `yt-dlp` (JSON, прогресс), обработка ошибок.
    *   **Результат:** Модуль для скачивания контента с видеоплатформ.
*   **Шаг 1.2: Обертка для `ffmpeg`**
    *   **Действие:** Создать модуль в бэкенде для взаимодействия с `ffmpeg` через `child_process`. Реализовать функции для:
        *   Извлечения аудиодорожки (`-vn -acodec copy`).
        *   Объединения аудиодорожек (`-filter_complex amix`).
        *   Замены/добавления аудиодорожки в видео (`-map`).
        *   Добавления субтитров (`-map`, `-c:s mov_text`).
        *   Конвертации формата (`-c:v`, `-c:a`).
    *   **Обработка:** Парсинг вывода `ffmpeg` (прогресс), обработка ошибок.
    *   **Результат:** Модуль для манипуляций с медиафайлами.
*   **Шаг 1.3: Обертка для `Demucs`**
    *   **Действие:** Создать модуль в бэкенде для вызова `Demucs` (предполагая Python-интерфейс или CLI). Реализовать функцию для разделения аудиофайла на вокал и инструментал.
    *   **Обработка:** Обработка путей к файлам, ожидание завершения, обработка ошибок.
    *   **Результат:** Модуль для разделения аудио.
*   **Шаг 1.4: Обертка для `Soundtouch`**
    *   **Действие:** Создать модуль в бэкенде для вызова `soundstretch` (CLI утилиты Soundtouch). Реализовать функцию для изменения темпа аудио без изменения тона.
    *   **Обработка:** Управление параметрами (`-tempo`), обработка ошибок.
    *   **Результат:** Модуль для пост-обработки синтезированного аудио.
*   **Шаг 1.5: Клиент для OpenAI API**
    *   **Действие:** Создать модуль в бэкенде для взаимодействия с OpenAI API (Whisper STT, Translation, TTS). Использовать официальную библиотеку `openai` или `axios`/`node-fetch`. Реализовать функции для:
        *   Распознавания речи (Speech-to-Text).
        *   Перевода текста.
        *   Синтеза речи (Text-to-Speech).
    *   **Обработка:** Обработка API-ключей (будет уточнено в Фазе 6), управление запросами/ответами, обработка ошибок API.
    *   **Результат:** Модуль для взаимодействия с облачными сервисами OpenAI.
*   **Шаг 1.6: Базовая структура для оффлайн моделей (Заглушки)**
    *   **Действие:** Создать интерфейсы/заглушки в бэкенде для взаимодействия с Whisper (локально), Vosk, Fish Speech, Ollama. На данном этапе реализовать только базовую структуру без полной интеграции.
    *   **Результат:** Подготовленная архитектура для последующей интеграции оффлайн-моделей.

**Фаза 2: Фронтенд - Базовый UI и взаимодействие**

*   **Шаг 2.1: Создание главного окна (UI Shell)**
    *   **Действие:** Используя React и Ant Design, создать базовую структуру главного окна: левая панель для ввода данных, правая панель для отображения прогресса/логов.
    *   **Компоненты:** `Layout`, `Input`, `Button`, `Select`, `Typography`, `List` (для логов).
    *   **Результат:** Визуальная структура основного экрана приложения.
*   **Шаг 2.2: Создание окна настроек (UI Shell)**
    *   **Действие:** Создать базовую структуру окна/модального окна/страницы настроек с использованием React и Ant Design. Добавить поля для API ключа OpenAI и заглушки для выбора моделей (STT, Translate, TTS).
    *   **Компоненты:** `Modal` или отдельный роут, `Form`, `Input`, `Select`, `Button`.
    *   **Результат:** Визуальная структура экрана настроек.
*   **Шаг 2.3: Связывание UI и бэкенда (Базовое)**
    *   **Действие:** Подключить элементы управления на главном экране (поле ввода URL, кнопка "Старт") к соответствующим функциям бэкенда через IPC, используя API, созданное на Шаге 0.4. Реализовать отображение простого статуса ("Idle", "Processing", "Done", "Error") на правой панели.
    *   **Логика:** Обработчики `onClick`, `onChange` на фронтенде вызывают функции IPC. Бэкенд отправляет события статуса через IPC на фронтенд.
    *   **Результат:** Возможность запустить процесс (пока без реальной логики) и увидеть изменение статуса.

**Фаза 3: Реализация основного пайплайна обработки видео (Бэкенд)**

*   **Шаг 3.1: Оркестратор процесса**
    *   **Действие:** Создать главный модуль/сервис в бэкенде, который будет управлять всем процессом обработки видео шаг за шагом. Он будет вызывать обертки из Фазы 1 в нужной последовательности.
    *   **Логика:** Определить состояния процесса (Downloading, Transcribing, Translating и т.д.). Реализовать асинхронное выполнение шагов (`async/await`). Использовать систему событий или колбэков для уведомления фронтенда о прогрессе и статусе через IPC.
    *   **Результат:** Центральный контроллер для всего рабочего процесса.
*   **Шаг 3.2: Реализация шага "Загрузка видео" (5.1)**
    *   **Действие:** Интегрировать обертку `yt-dlp` (Шаг 1.1) в оркестратор. Реализовать логику:
        *   Получение информации по URL.
        *   Определение языка (если возможно).
        *   Загрузка видео и/или аудио (сохранение в `temp`).
        *   Загрузка оригинальных субтитров (если есть, сохранение в `temp`).
        *   Отправка прогресса загрузки на фронтенд через IPC.
        *   Реализация отмены операции (убийство процесса `yt-dlp`).
    *   **Вход:** URL, папка назначения.
    *   **Выход:** Пути к скачанным файлам (видео, аудио, субтитры), метаданные.
*   **Шаг 3.3: Реализация шага "Распознавание речи" (5.2)**
    *   **Действие:** Интегрировать обертки `ffmpeg` (Шаг 1.2), `Demucs` (Шаг 1.3) и OpenAI/локальный STT (Шаг 1.5/1.6) в оркестратор. Логика:
        *   Извлечь аудио, если не скачано отдельно (`ffmpeg`).
        *   *Опционально (сделать настраиваемым):* Разделить вокал/инструментал (`Demucs`). Сохранить обе дорожки. Использовать вокальную дорожку для STT.
        *   Если оригинальные субтитры не скачаны, выполнить распознавание (сначала OpenAI, позже добавить локальные) вокальной (или полной) аудиодорожки.
        *   Сохранить результат в формате VTT (`temp/{filename}.original.vtt`).
    *   **Вход:** Путь к аудиофайлу (или видеофайлу), путь к оригинальным субтитрам (если есть).
    *   **Выход:** Путь к файлу VTT с распознанной речью, путь к инструментальной дорожке (если использовался Demucs).
*   **Шаг 3.4: Реализация шага "Перевод текста" (5.3)**
    *   **Действие:** Интегрировать OpenAI/Ollama (Шаг 1.5/1.6) в оркестратор. Логика:
        *   Прочитать VTT файл с оригинальным текстом.
        *   Отправить текст на перевод (OpenAI или Ollama, согласно настройкам).
        *   Сохранить переведенные субтитры в формате VTT (`temp/{filename}.translated.vtt`).
    *   **Вход:** Путь к оригинальному VTT файлу, целевой язык.
    *   **Выход:** Путь к переведенному VTT файлу.
*   **Шаг 3.5: Реализация шага "Синтез речи" (5.4)**
    *   **Действие:** Интегрировать OpenAI/локальный TTS (Шаг 1.5/1.6) и `Soundtouch` (Шаг 1.4) в оркестратор. Логика:
        *   Прочитать переведенный VTT файл.
        *   Для каждого сегмента VTT:
            *   Синтезировать речь (OpenAI TTS или локальный).
            *   *Важно:* Рассчитать длительность оригинального сегмента и синтезированного. Если синтезированный длиннее, использовать `Soundtouch` для ускорения (до 1.5x). Если короче, добавить тишину или слегка замедлить (`Soundtouch`).
            *   Сохранить/объединить обработанные аудиосегменты в одну аудиодорожку (`temp/{filename}.translated.wav/mp3`). *Альтернатива: генерировать аудио для каждого сегмента и потом склеивать ffmpeg'ом по таймкодам VTT.*
    *   **Вход:** Путь к переведенному VTT файлу, путь к оригинальному аудио (для таймингов), настройки голоса/TTS.
    *   **Выход:** Путь к синтезированной и подогнанной по времени аудиодорожке перевода.
*   **Шаг 3.6: Реализация шага "Обработка и объединение видео" (5.5)**
    *   **Действие:** Интегрировать `ffmpeg` (Шаг 1.2) в оркестратор. Логика:
        *   *Если использовался Demucs:* Объединить (`amix`) синтезированную аудиодорожку перевода с инструментальной дорожкой (`ffmpeg`).
        *   Взять исходное видео.
        *   Удалить оригинальную аудиодорожку (или оставить как дополнительную).
        *   Добавить новую микшированную (или просто синтезированную) аудиодорожку как основную (`-map`).
        *   Добавить оригинальные и переведенные субтитры (`-map`, `-c:s mov_text`).
        *   Установить метаданные языка для аудио и субтитров.
        *   Сохранить финальное видео в выбранную пользователем папку (`{selected_folder}/{filename}.output.mp4` или другой совместимый формат).
    *   **Вход:** Путь к исходному видео, путь к синтезированной/микшированной аудиодорожке, пути к оригинальным и переведенным VTT, путь к инструментальной дорожке (если есть), папка назначения.
    *   **Выход:** Финальный видеофайл с переводом.

**Фаза 4: Фронтенд - Отображение прогресса и UI/UX улучшения**

*   **Шаг 4.1: Детализированное отображение прогресса**
    *   **Действие:** Настроить фронтенд для приема и отображения детальных сообщений о прогрессе и логах от бэкенда через IPC. Отображать текущий шаг (Загрузка, Распознавание и т.д.), процент выполнения (если доступно, например, при скачивании или обработке ffmpeg), и логи/ошибки в реальном времени на правой панели.
    *   **Компоненты:** `Progress`, `List`, `Typography.Text code`.
    *   **Результат:** Информативный интерфейс, показывающий ход выполнения задачи.
*   **Шаг 4.2: Реализация UI главного экрана (6.1)**
    *   **Действие:** Завершить реализацию главного экрана:
        *   Поле ввода ссылки.
        *   Кнопка выбора директории (`dialog.showOpenDialog`).
        *   Выпадающие списки языков (заполнить статически или динамически, если возможно).
        *   Кнопка "Старт"/"Отмена" (логика отмены должна быть связана с оркестратором на бэкенде).
    *   **Результат:** Функциональный главный экран для запуска обработки.
*   **Шаг 4.3: Реализация UI экрана настроек (6.2)**
    *   **Действие:** Завершить реализацию экрана настроек:
        *   Поле для ввода API-ключа OpenAI (тип password).
        *   Селекторы для выбора STT, LLM, TTS (OpenAI / Local).
        *   Селектор для выбора голоса TTS (список должен обновляться в зависимости от выбранного TTS).
        *   Реализовать сохранение настроек (см. Шаг 6.3).
    *   **Результат:** Функциональный экран настроек.

**Фаза 5: Оффлайн-режим и управление зависимостями**

*   **Шаг 5.1: Интеграция локальных моделей (STT, Translate, TTS)**
    *   **Действие:** Реализовать фактическую интеграцию с локальными моделями, заменяя заглушки из Шага 1.6:
        *   **Whisper/Vosk:** Настроить вызов локальной модели Whisper (например, через Python-скрипт или C++ биндинги) или Vosk.
        *   **Ollama:** Реализовать клиент для Ollama API (локальный сервер) для перевода текста.
        *   **Fish Speech:** Настроить вызов Fish Speech для синтеза речи.
    *   **Логика:** Оркестратор должен использовать соответствующие модули в зависимости от настроек пользователя.
    *   **Результат:** Возможность выполнять весь пайплайн без подключения к интернету (кроме скачивания видео).
*   **Шаг 5.2: Управление внешними зависимостями (5.6)**
    *   **Действие:** Реализовать на бэкенде механизм проверки наличия `yt-dlp`, `ffmpeg`, `Demucs`, `Soundtouch` при запуске приложения.
    *   **Логика:** Проверять наличие исполняемых файлов в PATH или в предопределенной папке внутри приложения. Если утилита отсутствует, инициировать ее загрузку (например, с GitHub Releases) и сохранение в папку приложения. Показывать прогресс загрузки пользователю.
    *   **Результат:** Приложение самодостаточно устанавливает необходимые утилиты.
*   **Шаг 5.3: Управление локальными моделями (Загрузка и установка)**
    *   **Действие:** Реализовать механизм загрузки и установки локальных моделей (Whisper, Fish Speech веса, модели для Ollama), если пользователь выбирает их в настройках.
    *   **Логика:** При выборе локальной модели в настройках проверять ее наличие. Если отсутствует, показывать пользователю окно/индикатор загрузки и скачивать необходимые файлы моделей в определенную директорию (`userData` или аналогичную). Предупреждать о размере и времени загрузки.
    *   **Результат:** Автоматизированная установка оффлайн-моделей по выбору пользователя.

**Фаза 6: Обработка ошибок, безопасность и оптимизация**

*   **Шаг 6.1: Обработка ошибок и исключений (7)**
    *   **Действие:** Реализовать надежную обработку ошибок на всех этапах:
        *   Проверка доступности API (OpenAI, YouTube) с предложением VPN (7.1).
        *   Валидация API ключа OpenAI при вводе/использовании (7.2).
        *   Обработка ошибок сети (повторные попытки для API, возобновление для `yt-dlp`, если возможно) (7.3).
        *   Перехват ошибок от `child_process` (stderr).
        *   Отображение понятных сообщений об ошибках на фронтенде.
    *   **Результат:** Стабильное приложение, информирующее пользователя о проблемах.
*   **Шаг 6.2: Безопасность (8.3)**
    *   **Действие:** Реализовать безопасное хранение API-ключей.
    *   **Инструменты:** Использовать `electron-store` с опцией шифрования или `keytar` для системного хранилища учетных данных.
    *   **Логика:** Ключи не должны храниться в открытом виде.
    *   **Результат:** Повышенная безопасность пользовательских данных.
*   **Шаг 6.3: Хранение настроек (8.3)**
    *   **Действие:** Реализовать сохранение настроек приложения (выбранные языки, папка сохранения, выбор моделей, API-ключи) в постоянном хранилище.
    *   **Инструменты:** `electron-store` (хранит в JSON-файле в папке `userData`).
    *   **Результат:** Настройки сохраняются между запусками приложения.
*   **Шаг 6.4: Кэширование и возобновление (8.2)**
    *   **Действие:** Реализовать сохранение промежуточных файлов (скачанное видео/аудио, VTT, синтезированное аудио) в папку `temp` внутри выбранной пользователем директории. При запуске обработки для того же URL проверять наличие и актуальность промежуточных файлов, чтобы пропустить уже выполненные шаги.
    *   **Логика:** Оркестратор перед выполнением каждого шага проверяет наличие нужного выходного файла в `temp`. Если файл есть, шаг пропускается. Реализовать очистку `temp` папки по завершению или по запросу пользователя.
    *   **Результат:** Ускорение повторной обработки, экономия ресурсов и API-вызовов.
*   **Шаг 6.5: Асинхронность и предотвращение блокировки UI (8.1)**
    *   **Действие:** Убедиться, что все длительные операции (вызовы API, работа с файлами, запуск внешних утилит) выполняются асинхронно в основном процессе Electron и не блокируют UI (процесс рендерера). Использовать `async/await`, `Promises`, и возможно `worker_threads` для особо тяжелых CPU-bound задач (хотя большинство здесь I/O-bound или внешние процессы).
    *   **Результат:** Отзывчивый пользовательский интерфейс во время обработки.

**Фаза 7: Первый запуск и Завершение**

*   **Шаг 7.1: Логика первого запуска (8.4)**
    *   **Действие:** Реализовать проверку при первом запуске приложения.
    *   **Логика:** Проверять флаг "первый запуск" в `electron-store`. Если это первый запуск:
        1.  Показать окно/модальное окно настроек.
        2.  Если пользователь выбирает локальные модели, запустить процесс их скачивания/установки (Шаг 5.3), показывая прогресс.
        3.  После завершения настроек/скачивания показать главное окно.
        4.  Установить флаг "первый запуск" в `false`.
    *   **Результат:** Корректная начальная настройка приложения пользователем.
*   **Шаг 7.2: Тестирование**
    *   **Действие:** Провести комплексное тестирование:
        *   Тестирование отдельных модулей (unit tests, если применимо).
        *   Тестирование интеграции (вызовы утилит, API).
        *   Тестирование полного пайплайна на разных видео (YouTube, другие платформы, разные длительности, наличие/отсутствие субтитров).
        *   Тестирование UI/UX.
        *   Тестирование обработки ошибок.
        *   Тестирование на разных ОС (Windows, macOS, Linux).
    *   **Результат:** Выявление и исправление ошибок.
*   **Шаг 7.3: Сборка и упаковка**
    *   **Действие:** Настроить сборку приложения для целевых платформ (Windows, macOS, Linux).
    *   **Инструменты:** `electron-builder` или `electron-forge`.
    *   **Конфигурация:** Настроить иконки, метаданные, подпись кода (если требуется). Убедиться, что все внешние утилиты (или их загрузчики) включены в сборку.
    *   **Результат:** Готовые дистрибутивы приложения.

---

Этот план обеспечивает пошаговую разработку с постепенным наращиванием функциональности и учетом зависимостей между компонентами. Каждый шаг имеет четкую цель и результат, что должно быть удобно для выполнения ИИ-агентом. Важно регулярно проводить тестирование после завершения каждой фазы или крупного шага.